# Потоковая аналитика продаж в реальном времени  
## Реализация с использованием Apache Kafka и Spark Structured Streaming  

---

###  Цель проекта

Разработка системы потоковой аналитики для централизованного сбора, передачи и обработки данных о продажах в режиме реального времени. Проект имитирует работу распределённой сети магазинов, где:

- Каждый магазин генерирует и отправляет данные о чеках.
- Данные агрегируются централизованно.
- Система обеспечивает непрерывный мониторинг выручки по магазинам с использованием оконной агрегации и обработки событий по временным меткам.

---

###  Технологический стек

| Компонент | Назначение |
|---------|----------|
| **Apache Kafka** | Брокер сообщений для приёма, буферизации и доставки потока событий |
| **Python (kafka-python)** | Реализация продюсера — генерация событий о продажах |
| **Spark Structured Streaming** | Обработка потоковых данных: агрегация, оконные вычисления, управление задержками |
| **Docker** | Контейнеризация Kafka и Zookeeper для локального развёртывания |
| **PySpark** | Реализация Spark-приложения на языке Python |

---

### Архитектура системы

```
[Магазины]
    ↓ (события о продажах)
[Продюсеры (producer.py)]
    ↓ (публикация в Kafka)
[Kafka (топик: sales)]
    ↓ (потребление потока)
[Spark Streaming (streaming.py)]
    ↓ (агрегация в реальном времени)
[Консоль / Система аналитики]
```

---

### Генератор событий (`producer.py`)

Генерирует поток событий о продажах с интервалом 1 секунда.  
Каждое событие представлено в формате JSON и содержит следующие поля:

| Поле | Описание |
|------|--------|
| `store` | Идентификатор магазина (используется как ключ для партиционирования в Kafka) |
| `item` | Наименование товара |
| `price` | Стоимость товара (в условных единицах) |
| `ts` | Временная метка события в формате Unix timestamp (event time) |

События отправляются в топик Kafka `sales`.

---

###   Apache Kafka (в Docker-контейнерах)

- Запускается в изолированной среде с использованием Docker.
- Обеспечивает:
  - Надёжную доставку сообщений.
  - Масштабируемость и отказоустойчивость.
  - Поддержку множества продюсеров и консьюмеров.
- Топик: `sales`, количество партиций — настраивается.

---

###   Spark Streaming (`streaming.py`)

Потребляет данные из топика Kafka `sales` и выполняет следующие операции:

1. **Чтение потока**  
   Подключение к Kafka и чтение сообщений в виде структурированного потока.

2. **Парсинг JSON**  
   Преобразование строковых сообщений в структурированные данные с помощью схемы.

3. **Обработка временных меток**  
   Преобразование Unix-времени (`ts`) в тип `timestamp` для использования в event-time окнах.

4. **Оконная агрегация**  
   - Применение 30-секундных окон по времени события (`event time`).  
   - Группировка по магазину (`store`) и временному окну.  
   - Подсчёт суммарной выручки (`total_revenue_int`).

5. **Обработка задержек (late data)**  
   Использование `withWatermark("event_time", "30 seconds")` для управления событиями с опозданием.

6. **Вывод результатов**  
   Результаты агрегации выводятся в консоль каждые 10 секунд (по триггеру `processingTime`).

---

###  Пример выходных данных

```plaintext
+-------+------------------+-------------------+-------------------+
|store  |total_revenue_int |window_start       |window_end         |
+-------+------------------+-------------------+-------------------+
|store-1|287               |2025-09-02 10:30:00|2025-09-02 10:30:30|
|store-2|315               |2025-09-02 10:30:00|2025-09-02 10:30:30|
+-------+------------------+-------------------+-------------------+
```

> Интерпретация: в интервале с 10:30:00 по 10:30:30 магазин `store-1` заработал 287 у.е., `store-2` — 315 у.е.

---

### Ключевые особенности системы

| Характеристика | Описание |
|---------------|--------|
| **Режим реального времени** | Непрерывная обработка данных с минимальной задержкой |
| **Event-time обработка** | Агрегация по времени события, а не времени поступления |
| **Оконные вычисления** | 30-секундные фиксированные окна для агрегации выручки |
| **Управление задержками** | `withWatermark` позволяет обрабатывать опоздавшие события в пределах 30 секунд |
| **Масштабируемость** | Поддержка большого числа магазинов за счёт партиционирования по ключу `store` |
| **Отказоустойчивость** | Возможность восстановления состояния из checkpoint-директории (при необходимости) |

---

###   Запуск системы

1. **Запустить инфраструктуру (Kafka + Zookeeper)**  
   ```bash
   docker-compose up -d
   ```

2. **Создать топик Kafka `sales`**  
   ```bash
   docker exec -it kafka kafka-topics.sh --create --topic sales --bootstrap-server localhost:9092 --partitions 3 --replication-factor 1
   ```

3. **Запустить генератор событий**  
   ```bash
   python producer.py
   ```

4. **Запустить Spark-приложение**  
   ```bash
   spark-submit streaming.py
   ```

---

### Структура проекта

```
realtime-sales-analytics/
├── producer.py           # Генератор событий о продажах
├── streaming.py          # Spark-приложение для потоковой обработки
├── docker-compose.yml    # Оркестрация Kafka и Zookeeper
├── requirements.txt      # Зависимости Python
└── README.md             # Документация проекта
```

---

### Примечания

- Для промышленного использования рекомендуется настроить `checkpointLocation` в Spark для обеспечения отказоустойчивости.
- Возможна интеграция с внешними системами: базами данных, дашбордами (например, через Kafka Connect или вывод в PostgreSQL/Redis).
- Система легко масштабируется на десятки и сотни магазинов.

---

**Разработано для демонстрации возможностей потоковой обработки данных в реальном времени с использованием современных Big Data технологий.**
