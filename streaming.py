from pyspark.sql import SparkSession
from pyspark.sql.functions import from_json, col, window, sum
from pyspark.sql.types import StructType, StringType, DoubleType, IntegerType

# ================================
# –°–æ–∑–¥–∞–Ω–∏–µ SparkSession
# ================================
spark = SparkSession.builder \
    .appName("SalesStreaming") \
    .master("local[*]") \
    .config("spark.jars.packages", "org.apache.spark:spark-sql-kafka-0-10_2.12:3.4.1") \
    .getOrCreate()

spark.sparkContext.setLogLevel("WARN")

# ================================
# –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å—Ö–µ–º—ã
# ================================
schema = StructType() \
    .add("store", StringType()) \
    .add("item", StringType()) \
    .add("price", DoubleType()) \
    .add("ts", IntegerType())

# ================================
# –ß—Ç–µ–Ω–∏–µ –∏–∑ Kafka
# ================================
df = spark.readStream \
    .format("kafka") \
    .option("kafka.bootstrap.servers", "localhost:9092") \
    .option("subscribe", "sales") \
    .load()

# ================================
# –ü–∞—Ä—Å–∏–Ω–≥ –∏ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏
# ================================
parsed = df.select(
    col("key").cast("string").alias("store"),
    from_json(col("value").cast("string"), schema).alias("data"),
    col("timestamp").alias("kafka_ingestion_time")
).select(
    "store",
    "data.item",
    "data.price",
    "data.ts",
    "kafka_ingestion_time"
)

# –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º Unix-–≤—Ä–µ–º—è –≤ timestamp
with_event_time = parsed \
    .withColumn("event_time", col("ts").cast("timestamp"))

# –î–æ–±–∞–≤–ª—è–µ–º watermark
with_watermark = with_event_time \
    .withWatermark("event_time", "30 seconds")

# –ê–≥—Ä–µ–≥–∞—Ü–∏—è –ø–æ 30-—Å–µ–∫—É–Ω–¥–Ω—ã–º –æ–∫–Ω–∞–º
windowed_sales = with_watermark \
    .groupBy("store", window(col("event_time"), "30 seconds")) \
    .agg(
        sum("price").alias("total_revenue"),
        sum("price").cast("int").alias("total_revenue_int"),
        col("window.start").alias("window_start"),
        col("window.end").alias("window_end")
    ) \
    .select(
        "store",
        "total_revenue_int",
        "window_start",
        "window_end"
    )

# ================================
# –ó–∞–ø—É—Å–∫ –ø–æ—Ç–æ–∫–∞
# ================================
query = (
    windowed_sales.writeStream
    .outputMode("update")  # –æ–±–Ω–æ–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –∏–∑–º–µ–Ω—ë–Ω–Ω—ã–µ –æ–∫–Ω–∞
    .format("console")
    .option("truncate", "false")
    .trigger(processingTime='10 seconds')  # —Ç—Ä–∏–≥–≥–µ—Ä –∫–∞–∂–¥—ã–µ 10 —Å–µ–∫
    .start()
)

print("‚úÖ Spark –Ω–∞—á–∞–ª —Å–ª—É—à–∞—Ç—å —Ç–æ–ø–∏–∫ 'sales'...")
print("üìä –ê–≥—Ä–µ–≥–∞—Ü–∏—è –ø–æ 30-—Å–µ–∫—É–Ω–¥–Ω—ã–º –æ–∫–Ω–∞–º. –û–∂–∏–¥–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö...")

# ================================
# –£–¥–µ—Ä–∂–∞–Ω–∏–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
# ================================
query.awaitTermination()